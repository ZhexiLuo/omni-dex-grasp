"""ğŸ“ FoundationPose 6D pose estimation server.

POST /predict - Estimate 6D object pose from RGB + depth + mesh.

Usage: conda activate fdpose && python -m recons.server.fdpose
"""
import base64
import io
import sys
import threading
from dataclasses import dataclass
from pathlib import Path

_FP_DIR = Path(__file__).resolve().parents[2] / "thirdparty" / "FoundationPose"
sys.path.insert(0, str(_FP_DIR))

import cv2
import hydra
import numpy as np
import torch
import trimesh
import uvicorn
from fastapi import FastAPI, Request
from omegaconf import DictConfig
from PIL import Image
from pydantic import BaseModel

from estimater import FoundationPose, ScorePredictor, PoseRefinePredictor
from Utils import draw_posed_3d_box, draw_xyz_axis
import nvdiffrast.torch as dr


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§  Model
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class FDPoseModel:
    """ğŸ“ FoundationPose model wrapper."""
    estimator: FoundationPose
    device: str
    cfg: DictConfig

    def __post_init__(self):
        self._lock = threading.Lock()

    @classmethod
    def from_config(cls, cfg: DictConfig) -> "FDPoseModel":
        """ğŸš€ Initialize FoundationPose (scorer/refiner/glctx loaded once)."""
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸš€ Loading FoundationPose on {device}...")

        print("  ğŸ“Š Loading ScorePredictor...")
        scorer = ScorePredictor()
        print("  ğŸ”§ Loading PoseRefinePredictor...")
        refiner = PoseRefinePredictor()
        print("  ğŸ¨ Creating CUDA rasterize context...")
        glctx = dr.RasterizeCudaContext()

        # ğŸ“¦ Initialize with dummy mesh (first request will reset_object)
        dummy_mesh = trimesh.primitives.Box()
        debug_dir = str(_FP_DIR / "debug")
        est = FoundationPose(
            model_pts=dummy_mesh.vertices.copy(),
            model_normals=dummy_mesh.vertex_normals.copy(),
            mesh=dummy_mesh,
            scorer=scorer,
            refiner=refiner,
            glctx=glctx,
            debug=cfg.inference.debug,
            debug_dir=debug_dir,
        )

        print("âœ… FoundationPose loaded!")
        return cls(estimator=est, device=device, cfg=cfg)

    def estimate_pose(
        self,
        image_path: str,
        depth: np.ndarray,
        obj_mesh_path: str,
        bbox: list[float],
        intrinsics: np.ndarray,
    ) -> dict:
        """ğŸ“ Estimate 6D pose for a single object."""
        with self._lock:
            # 1ï¸âƒ£ Load RGB
            rgb = np.array(Image.open(image_path).convert("RGB"))
            H, W = rgb.shape[:2]

            # ğŸ“ Validate depth-RGB shape match
            if depth.shape != (H, W):
                raise ValueError(f"Depth shape {depth.shape} != RGB shape ({H}, {W})")

            # 2ï¸âƒ£ Load mesh & reset estimator (float32 required by FoundationPose)
            mesh = trimesh.load(obj_mesh_path, force="mesh")
            mesh.vertices = mesh.vertices.astype(np.float32)
            self.estimator.reset_object(
                model_pts=mesh.vertices.copy(),
                model_normals=mesh.vertex_normals.copy().astype(np.float32),
                mesh=mesh,
            )

            # 3ï¸âƒ£ Build mask from bbox (clip to image bounds)
            x1, y1, x2, y2 = [int(v) for v in bbox]
            x1, x2 = max(0, x1), min(W, x2)
            y1, y2 = max(0, y1), min(H, y2)
            if x2 <= x1 or y2 <= y1:
                raise ValueError(f"Degenerate bbox after clipping: [{x1},{y1},{x2},{y2}] for image ({H},{W})")
            mask = np.zeros((H, W), dtype=bool)
            mask[y1:y2, x1:x2] = True

            # 4ï¸âƒ£ Register (single-frame pose estimation)
            pose = self.estimator.register(
                K=intrinsics,
                rgb=rgb,
                depth=depth,
                ob_mask=mask,
                iteration=self.cfg.inference.est_refine_iter,
            )
            # pose: (4,4) numpy array, object-in-camera

            # âš ï¸ Detect degenerate pose (identity rotation = insufficient valid depth)
            is_degenerate = np.allclose(pose[:3, :3], np.eye(3), atol=1e-6)

            # 5ï¸âƒ£ Generate visualization
            vis = self._generate_vis(rgb, pose, mesh, intrinsics)

            return {"pose": pose, "vis": vis, "is_degenerate": is_degenerate}

    def _generate_vis(
        self,
        rgb: np.ndarray,
        pose: np.ndarray,
        mesh: trimesh.Trimesh,
        K: np.ndarray,
    ) -> np.ndarray:
        """ğŸ¨ Generate pose visualization with 3D bbox and axes. Returns BGR image."""
        to_origin, extents = trimesh.bounds.oriented_bounds(mesh)
        bbox_3d = np.stack([-extents / 2, extents / 2], axis=0).reshape(2, 3)
        center_pose = pose @ np.linalg.inv(to_origin)

        vis_bgr = cv2.cvtColor(rgb.copy(), cv2.COLOR_RGB2BGR)
        vis_bgr = draw_posed_3d_box(
            K, img=vis_bgr, ob_in_cam=center_pose, bbox=bbox_3d,
        )
        vis_bgr = draw_xyz_axis(
            vis_bgr, ob_in_cam=center_pose, scale=0.1,
            K=K, thickness=3, transparency=0, is_input_rgb=False,
        )
        return vis_bgr


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒ API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class PredictRequest(BaseModel):
    image_path: str
    depth_b64: str                     # ğŸ“ base64 encoded depth npy (H,W) float32, meters
    obj_mesh_path: str
    bbox: list[float]                  # [x1, y1, x2, y2]
    intrinsics: list[list[float]]      # 3x3 camera intrinsics matrix


class PredictResponse(BaseModel):
    status: str
    message: str
    pose: list[list[float]] = []       # ğŸ“ 4x4 pose matrix (object-in-camera)
    pose_vis_b64: str = ""             # ğŸ¨ base64 encoded visualization


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ Helpers
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def decode_array_b64(b64_str: str) -> np.ndarray:
    """ğŸ“ Decode base64 npy string to numpy array."""
    arr_bytes = base64.b64decode(b64_str)
    return np.load(io.BytesIO(arr_bytes))


def encode_image_b64(img_bgr: np.ndarray) -> str:
    """ğŸ–¼ï¸ Encode BGR image to base64 PNG string."""
    _, buffer = cv2.imencode(".png", img_bgr)
    return base64.b64encode(buffer).decode("utf-8")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ Server
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

app = FastAPI(title="ğŸ“ FoundationPose Server")


@app.post("/predict", response_model=PredictResponse)
def predict(req: PredictRequest, request: Request) -> PredictResponse:
    """ğŸ“ Estimate 6D object pose."""
    model: FDPoseModel = request.app.state.model
    print(f"\n{'='*60}")
    print(f"ğŸ“¨ New request: {req.image_path}")

    # ğŸ“‹ Validate inputs
    image_path = Path(req.image_path)
    if not image_path.exists():
        return PredictResponse(status="error", message=f"Image not found: {req.image_path}")

    mesh_path = Path(req.obj_mesh_path)
    if not mesh_path.exists():
        return PredictResponse(status="error", message=f"Mesh not found: {req.obj_mesh_path}")

    K = np.array(req.intrinsics, dtype=np.float64)  # FoundationPose expects float64 K
    if K.shape != (3, 3):
        return PredictResponse(status="error", message=f"Intrinsics must be 3x3, got {K.shape}")

    if len(req.bbox) != 4:
        return PredictResponse(status="error", message=f"Bbox must be [x1,y1,x2,y2], got len={len(req.bbox)}")

    # ğŸ“ Decode depth
    depth = decode_array_b64(req.depth_b64)
    if depth.dtype != np.float32:
        depth = depth.astype(np.float32)

    print(f"  ğŸ“ Depth shape: {depth.shape}, range: [{depth.min():.3f}, {depth.max():.3f}] m")
    print(f"  ğŸ“¦ Bbox: {req.bbox}")
    print(f"  ğŸ§Š Mesh: {req.obj_mesh_path}")

    # ğŸ“ Estimate pose
    try:
        result = model.estimate_pose(
            image_path=str(image_path),
            depth=depth,
            obj_mesh_path=str(mesh_path),
            bbox=req.bbox,
            intrinsics=K,
        )
    except Exception as e:
        print(f"  âŒ Pose estimation failed: {e}")
        return PredictResponse(status="error", message=f"Pose estimation failed: {e}")

    # ğŸ“¦ Encode outputs
    pose_list = result["pose"].tolist()
    vis_b64 = encode_image_b64(result["vis"])

    status = "warning" if result["is_degenerate"] else "success"
    msg_suffix = " (âš ï¸ degenerate pose, may be unreliable)" if result["is_degenerate"] else ""

    print(f"  ğŸ“ Pose estimated! {'âš ï¸ DEGENERATE' if result['is_degenerate'] else 'âœ…'}")
    print(f"  ğŸ“ Translation: [{result['pose'][0,3]:.4f}, {result['pose'][1,3]:.4f}, {result['pose'][2,3]:.4f}]")
    print(f"ğŸ‰ Done!")

    return PredictResponse(
        status=status,
        message=f"Pose estimated for {mesh_path.stem}{msg_suffix}",
        pose=pose_list,
        pose_vis_b64=vis_b64,
    )


@hydra.main(config_path="../../cfg/model", config_name="fdpose", version_base=None)
def main(cfg: DictConfig) -> None:
    """ğŸš€ Start FDPose server with Hydra config."""
    app.state.model = FDPoseModel.from_config(cfg)
    print(f"ğŸŒ Server starting at http://{cfg.server.host}:{cfg.server.port}")
    uvicorn.run(app, host=cfg.server.host, port=cfg.server.port)


if __name__ == "__main__":
    main()
