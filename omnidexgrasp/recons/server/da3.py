"""ğŸŒŠ Depth-Anything-3 metric depth estimation server.

POST /predict - Estimate metric depth from single RGB image.

Usage: conda activate da3 && python -m recons.server.da3
"""
import base64
import io
import os
from dataclasses import dataclass
from pathlib import Path

import cv2
import hydra
import numpy as np
import torch
import uvicorn
from fastapi import FastAPI, Request
from omegaconf import DictConfig
from PIL import Image
from pydantic import BaseModel

from depth_anything_3.api import DepthAnything3


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§  Model
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class DA3Model:
    """ğŸŒŠ Depth-Anything-3 model wrapper."""
    model: DepthAnything3
    device: str
    cfg: DictConfig

    @classmethod
    def from_config(cls, cfg: DictConfig) -> "DA3Model":
        """ğŸš€ Load DA3 model from config."""
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸš€ Loading Depth-Anything-3 on {device}...")

        model = DepthAnything3.from_pretrained(cfg.model.pretrained).to(device)
        print(f"âœ… DA3 model loaded: {cfg.model.pretrained}")
        return cls(model=model, device=device, cfg=cfg)

    def predict_depth(self, image_path: str, intrinsics: np.ndarray) -> dict:
        """ğŸŒŠ Run metric depth estimation on a single image.

        Uses original image resolution for inference, then resizes back.
        """
        img = Image.open(image_path)
        original_h, original_w = img.height, img.width
        process_res = max(original_h, original_w)

        prediction = self.model.inference(
            image=[image_path],
            intrinsics=intrinsics[None, ...],  # (1, 3, 3)
            process_res=process_res,
        )
        depth = prediction.depth[0]  # (H, W) float32
        conf = prediction.conf[0] if prediction.conf is not None else None

        # ğŸ“ Resize to original resolution (DA3 rounds internally to multiples of 14)
        if depth.shape != (original_h, original_w):
            depth = cv2.resize(depth, (original_w, original_h), interpolation=cv2.INTER_LINEAR)
            if conf is not None:
                conf = cv2.resize(conf, (original_w, original_h), interpolation=cv2.INTER_LINEAR)

        return {
            "depth": depth.astype(np.float32),
            "conf": conf.astype(np.float32) if conf is not None else None,
            "is_metric": bool(prediction.is_metric),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒ API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class PredictRequest(BaseModel):
    image_path: str
    intrinsics: list[list[float]]  # 3x3 camera intrinsics matrix


class PredictResponse(BaseModel):
    status: str
    message: str
    depth_b64: str = ""      # ğŸ“ base64 encoded depth npy (H,W) float32, meters
    conf_b64: str = ""       # ğŸ“Š base64 encoded confidence npy (H,W) float32
    is_metric: bool = False
    depth_vis_b64: str = ""  # ğŸ¨ base64 encoded colormap visualization


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ Helpers
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def encode_array_b64(arr: np.ndarray) -> str:
    """ğŸ“ Encode numpy array to base64 npy string."""
    buf = io.BytesIO()
    np.save(buf, arr)
    return base64.b64encode(buf.getvalue()).decode("utf-8")


def generate_depth_vis(depth: np.ndarray) -> np.ndarray:
    """ğŸ¨ Generate colorized depth visualization."""
    d_norm = (depth - depth.min()) / (depth.max() - depth.min() + 1e-8) * 255
    d_uint8 = d_norm.astype(np.uint8)
    return cv2.applyColorMap(d_uint8, cv2.COLORMAP_INFERNO)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ Server
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

app = FastAPI(title="ğŸŒŠ Depth-Anything-3 Server")


@app.post("/predict", response_model=PredictResponse)
def predict(req: PredictRequest, request: Request) -> PredictResponse:
    """ğŸŒŠ Estimate metric depth from RGB image."""
    model: DA3Model = request.app.state.model
    print(f"\n{'='*60}")
    print(f"ğŸ“¨ New request: {req.image_path}")

    image_path = Path(req.image_path)
    if not image_path.exists():
        return PredictResponse(status="error", message=f"Image not found: {req.image_path}")

    K = np.array(req.intrinsics, dtype=np.float32)
    if K.shape != (3, 3):
        return PredictResponse(status="error", message=f"Intrinsics must be 3x3, got {K.shape}")

    result = model.predict_depth(str(image_path), K)

    # ğŸ“¦ Encode outputs to base64
    depth_b64 = encode_array_b64(result["depth"])
    conf_b64 = encode_array_b64(result["conf"]) if result["conf"] is not None else ""

    # ğŸ¨ Depth visualization
    vis = generate_depth_vis(result["depth"])
    _, vis_buffer = cv2.imencode(".png", vis)
    depth_vis_b64 = base64.b64encode(vis_buffer).decode("utf-8")

    h, w = result["depth"].shape
    print(f"  ğŸ“ Depth shape: ({h}, {w}), metric: {result['is_metric']}")
    print(f"  ğŸ“Š Depth range: [{result['depth'].min():.3f}, {result['depth'].max():.3f}] m")
    print(f"ğŸ‰ Done!")

    return PredictResponse(
        status="success",
        message=f"Depth estimated ({h}x{w}), metric={result['is_metric']}",
        depth_b64=depth_b64,
        conf_b64=conf_b64,
        is_metric=result["is_metric"],
        depth_vis_b64=depth_vis_b64,
    )


@hydra.main(config_path="../../cfg/model", config_name="da3", version_base=None)
def main(cfg: DictConfig) -> None:
    """ğŸš€ Start DA3 server with Hydra config."""
    app.state.model = DA3Model.from_config(cfg)
    print(f"ğŸŒ Server starting at http://{cfg.server.host}:{cfg.server.port}")
    uvicorn.run(app, host=cfg.server.host, port=cfg.server.port)


if __name__ == "__main__":
    main()
